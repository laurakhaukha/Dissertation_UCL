{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading necesary libraries\n",
    " import pandas as pd \n",
    " import numpy as np \n",
    " import os \n",
    " from matplotlib import pyplot as plt \n",
    " \n",
    " #Loading the datasets, and setting the datapathways\n",
    " DESCRIP_PATH = \"/Users/laurakhaukha/Desktop/Diss_data/SnomedCT_UKClinicalRF2_PRODUCTION_20241120T000001Z/Snapshot/Terminology/sct2_Description_UKCLSnapshot-en_GB1000000_20241120.txt\"\n",
    " RELASHION_PATH = \"/Users/laurakhaukha/Desktop/Diss_data/SnomedCT_UKClinicalRF2_PRODUCTION_20241120T000001Z/Snapshot/Terminology/sct2_Relationship_UKCLSnapshot_GB1000000_20241120.txt\"\n",
    " \n",
    " descrip_df = pd.read_csv(DESCRIP_PATH, header=0, delimiter=\"\\t\", dtype=str)\n",
    " relashion_df_ = pd.read_csv(RELASHION_PATH, delimiter=\"\\t\", dtype=str) \n",
    " \n",
    " \n",
    " # Create a smaller file copy to prevent memmory loss, for later use: COMBACK for randomisation\n",
    " relation_chunk = pd.read_csv(RELASHION_PATH, delimiter=\"\\t\", dtype=str, nrows=1000) # The first 1000 rows only \n",
    " descripnchunk = pd.read_csv(DESCRIP_PATH, delimiter=\"\\t\", dtype=str, nrows=1000) # The first 1000 rows only \n",
    " \n",
    " ########### Exploratory Data Analysis ############\n",
    " print(descrip_df.columns)  \n",
    " print(relashion_df_.columns)  \n",
    " \n",
    " # Viewing the shape of the data\n",
    " descrip_df.head(20)\n",
    " relashion_df_.head(20)\n",
    " relashion_df_.shape\n",
    " descrip_df.shape\n",
    " \n",
    " # Looking into counts per row/column\n",
    " descrip_df[\"id\"].value_counts()\n",
    " descrip_df[\"id\"].nunique()\n",
    " relashion_df_[\"id\"].value_counts()\n",
    " relashion_df_[\"id\"].nunique()\n",
    " \n",
    " # Checking for missing values \n",
    " print(descrip_df.isnull().sum())   #No missing values\n",
    " print(relashion_df_.isnull().sum())  # No missing values \n",
    " \n",
    " #Descriptive statistics, can not be done one th merged \n",
    " relashion_df_.describe()\n",
    " relashion_df_.summary()\n",
    " descrip_df.describe()\n",
    " descrip_df.summary()\n",
    " \n",
    " ####### Demopgraphic analysis: Which conditions are most common in the dataset\n",
    " \n",
    " # Creating a bar chart for the term frequencies within the dataset\n",
    " print(descrip_df.columns)\n",
    " print(relashion_df_.columns)\n",
    " v = descrip_df[\"term\"].value_counts()\n",
    " \n",
    " plt.figure(figsize=(20, 10))\n",
    " plt.bar(v.index, v.values)\n",
    " plt.xlabel(\"Term\")\n",
    " plt.ylabel(\"Count\")\n",
    " plt.title(\"Frequency of Terms/Diagnosis in Description Data\")\n",
    " plt.savefig(\"term_frequency.png\")\n",
    " plt.show(block=True) \n",
    " \n",
    " # Making a table instead: for term frequencies \n",
    " term_frequencies = descrip_df[\"term\"].value_counts().reset_index()\n",
    " print(term_frequencies.head(20))   #Displaying the most - frequent terms/ medical categories\n",
    " \n",
    " #Making a figure for the moduleId'\n",
    " m = descrip_df[\"term\"].value_counts()\n",
    " plt.figure(figsize=(12, 6))\n",
    " plt.bar(m.index, m.values)\n",
    " \n",
    " plt.xlabel(\"ModuleId\")\n",
    " plt.ylabel(\"Count\")\n",
    " plt.title(\"Frequency of ModuleId in Description Data\")\n",
    " plt.show(block=True)\n",
    " \n",
    " # Merging datasets\n",
    " #merged_dr_df = pd.merge(descrip_df, relashion_df_, on=\"id\", how=\"left\") # is this reasonable ?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
